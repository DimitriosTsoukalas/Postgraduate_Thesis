{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coefficient Investigation using the Logistic Regression algorithm\n",
    "\n",
    "This experiment ran on the question feature. It consists of some preprocessing steps that are mentioned below and of course the main process of applying the Logistic Regression algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here there are some sample questions from the question feature:\n",
      "\n",
      "0    Can you see more than 50% of a word on the per...\n",
      "1                             Is the persons' hair up?\n",
      "2                           Is the person's hair dyed?\n",
      "3                           Is the person's hair dyed?\n",
      "4           is the girl wearing anything on their head\n",
      "Name: Question, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "df = pd.read_csv(\"UniqueQuestions.csv\")\n",
    "df1 = df[\"Question\"]\n",
    "\n",
    "print \"Here there are some sample questions from the question feature:\"\n",
    "print\n",
    "print df1[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the DFCoef database\n",
    "\n",
    "Further information are provided in the thesis doc. This database, in general was created to support the experiment and run the algorithm which requires some binary values. These values were captured after manually checking, each of the FOUR words (eyes, wear, skin and hair) in the content of the question feature. The below is just an example of the \"hair\" word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "\n",
    "for items in range(len(df[\"Question\"])):\n",
    "    line = str(df[\"Question\"][items])\n",
    "    if \"hair\" in line:\n",
    "        #df[\"Blonde\"][items] == 1\n",
    "        sentences.append(1)\n",
    "    else:\n",
    "        #df[\"Blonde\"][items] == 0\n",
    "        sentences.append(0)\n",
    "        \n",
    "df[\"hair\"] = sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allsentences = []\n",
    "\n",
    "for items in df[\"Question\"]:\n",
    "    items = str(items)\n",
    "    sentence = []\n",
    "    for words in items.split():\n",
    "        #print words\n",
    "        pattern = re.search(r'(.*)(\\[comma])',words)\n",
    "        if pattern:\n",
    "            sentence.append(pattern.group(1).lower())\n",
    "        else:\n",
    "            sentence.append(words.lower())\n",
    "    allsentences.append(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lista=  []\n",
    "\n",
    "for items in allsentences:\n",
    "    captured = \" \".join(items)\n",
    "    lista.append(captured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listb = []\n",
    "\n",
    "for items in lista:\n",
    "    summing = []\n",
    "    items = items.split()\n",
    "    for words in items:\n",
    "        words = words.strip(\"\\',?.\")\n",
    "        #print words\n",
    "        if words not in stopwords.words(\"english\"):\n",
    "            summing.append(words)\n",
    "    listb.append(summing)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "liste = []\n",
    "\n",
    "for items in listb:\n",
    "    temporar = []\n",
    "    for words in items:\n",
    "        if words == \"wearing\":\n",
    "            continue\n",
    "        elif words == \"wear\":\n",
    "            continue\n",
    "        elif words == \"person\":\n",
    "            continue\n",
    "        else:\n",
    "            temporar.append(words)\n",
    "    liste.append(temporar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listc=  []\n",
    "\n",
    "for items in listb:\n",
    "    captured = \" \".join(items)\n",
    "    listc.append(captured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"questionsAsked\"] = listc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"questionsAsked\"],df[\"hair\"],random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<15831x1148 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 34607 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presenting results\n",
    "\n",
    "There are much more information about the results in the thesis document (doc file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993630220109\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print (roc_auc_score(y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficients\n",
    "\n",
    "The below table presents the 20 largest and the 20 smallest coefficients which were captured from the word \"hair\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest coefs:\n",
      "[u'nan' u'boy' u'girl' u'glasses' u'wearing' u'bangs' u'shirt' u'beard'\n",
      " u'asian' u'curley' u'white' u'beautiful' u'fashioned' u'male' u'looks'\n",
      " u'head' u'female' u'xxx' u'tall' u'lot']\n",
      "\n",
      "Largest coefs:\n",
      "[u'hair' u'haircut' u'hairs' u'haired' u'hairstyle' u'hairline' u'facial'\n",
      " u'strange' u'longhair' u'sitting' u'chair' u'receding' u'receeding'\n",
      " u'alternative' u'tied' u'less' u'somewhere' u'whether']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "print (\"Smallest coefs:\\n{}\\n\".format(feature_names[sorted_coef_index[:20]]))\n",
    "print (\"Largest coefs:\\n{}\\n\".format(feature_names[sorted_coef_index[:1-20:-1]]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
