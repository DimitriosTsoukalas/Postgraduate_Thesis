{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "\n",
    "In this experiment the \"questions feature\" is examined. Some preprocessing steps are applied before capturing the necessary value and filling DF0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1 - Importation\n",
    "\n",
    "In this phase, the libraries and the important feaures are imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QuestionNumber' 'FacesEliminated' 'Question' 'BoardNumber' 'ActionType'\n",
      " 'UniqueID' 'FacesEliminatedCount' 'FinalChoice' 'QuestionResponse']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"questions.csv\")\n",
    "\n",
    "print df.columns.values\n",
    "df1 = df[\"Question\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2 - Questions, answer and Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the person wearing glasses? Yes\n",
      "Does the person have bangs? Yes\n",
      "IMG_7942\n",
      "Does the person have bangs? No\n",
      "Does the person have blonde hair? No\n",
      "Does the person have short hair? Yes\n",
      "Does the person ave her hair tied up? Yes\n",
      "Does the person have her hair in a ponytail?  No\n",
      "Does the person have her hair in a bun? No\n",
      "IMG_7532\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for items in range(10):\n",
    "    if df1[items] == \"x\":\n",
    "        print df[\"FinalChoice\"][items]\n",
    "    else:\n",
    "        print df1[items],df[\"QuestionResponse\"][items]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3 - Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allsentences = []\n",
    "\n",
    "for items in df1:\n",
    "    sentence = []\n",
    "    for words in items.split():\n",
    "        #print words\n",
    "        pattern = re.search(r'(.*)(\\[comma])',words)\n",
    "        if pattern:\n",
    "            sentence.append(pattern.group(1).lower())\n",
    "        else:\n",
    "            sentence.append(words.lower())\n",
    "    allsentences.append(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is', 'the', 'person', 'wearing', 'glasses?']\n",
      "['does', 'the', 'person', 'have', 'bangs?']\n",
      "['x']\n",
      "['does', 'the', 'person', 'have', 'bangs?']\n",
      "['does', 'the', 'person', 'have', 'blonde', 'hair?']\n",
      "['does', 'the', 'person', 'have', 'short', 'hair?']\n",
      "['does', 'the', 'person', 'ave', 'her', 'hair', 'tied', 'up?']\n",
      "['does', 'the', 'person', 'have', 'her', 'hair', 'in', 'a', 'ponytail?']\n",
      "['does', 'the', 'person', 'have', 'her', 'hair', 'in', 'a', 'bun?']\n",
      "['x']\n"
     ]
    }
   ],
   "source": [
    "for items in range(10):\n",
    "    print allsentences[items]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 4 - Joining words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lista=  []\n",
    "\n",
    "for items in allsentences:\n",
    "    captured = \" \".join(items)\n",
    "    lista.append(captured)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 5 - Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listb = []\n",
    "\n",
    "for items in lista:\n",
    "    summing = []\n",
    "    items = items.split()\n",
    "    for words in items:\n",
    "        words = words.strip(\"\\',?.\")\n",
    "        #print words\n",
    "        if words not in stopwords.words(\"english\"):\n",
    "            summing.append(words)\n",
    "    listb.append(summing)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'wearing', 'glasses']\n",
      "['person', 'bangs']\n",
      "['x']\n",
      "['person', 'bangs']\n",
      "['person', 'blonde', 'hair']\n",
      "['person', 'short', 'hair']\n",
      "['person', 'ave', 'hair', 'tied']\n",
      "['person', 'hair', 'ponytail']\n",
      "['person', 'hair', 'bun']\n",
      "['x']\n"
     ]
    }
   ],
   "source": [
    "for items in range (10):\n",
    "    print listb[items]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 6 - Joining words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listc=  []\n",
    "\n",
    "for items in listb:\n",
    "    captured = \" \".join(items)\n",
    "    listc.append(captured)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 7 - Discovering most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 asian\n",
      "114 beard\n",
      "119 black\n",
      "103 blonde\n",
      "66 boy\n",
      "101 facial\n",
      "52 female\n",
      "61 girl\n",
      "492 glasses\n",
      "723 hair\n",
      "157 life\n",
      "129 long\n",
      "79 male\n",
      "1663 person\n",
      "59 say\n",
      "367 shirt\n",
      "91 short\n",
      "56 tall\n",
      "106 undershirt\n",
      "164 wear\n",
      "486 wearing\n",
      "143 white\n",
      "69 xxx\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus  import stopwords\n",
    "\n",
    "\n",
    "total = []\n",
    "\n",
    "for items in range(len(listc)):\n",
    "    listc[items] = str(listc[items])\n",
    "    example1 = BeautifulSoup(listc[items],\"lxml\")\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\",\" \",example1.get_text() )\n",
    "    words = letters_only.split()\n",
    "    for w in words:\n",
    "        if w not in stopwords.words(\"english\"):\n",
    "            total.append(w)\n",
    "    #words = for w in words if not w in stopwords.words(\"english\")]\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000) \n",
    "\n",
    "train_data_features = vectorizer.fit_transform(total)\n",
    "train_data_features = train_data_features.toarray()\n",
    "\n",
    "vocab = vectorizer.get_feature_names()\n",
    "#print vocab\n",
    "\n",
    "#Calculate the total count of words\n",
    "dist = np.sum(train_data_features, axis=0)\n",
    "for tag, count in zip(vocab, dist):\n",
    "    if count>50:\n",
    "        print count,tag\n",
    "    #print count, tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
